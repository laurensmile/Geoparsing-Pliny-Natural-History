{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d74066e",
   "metadata": {},
   "source": [
    "# Perform NER on Book 4 (BIO format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b575ad8a",
   "metadata": {},
   "source": [
    "The notebook contains the code to perform Flair NER and spaCy NER on Book 4 and structure the output in the BIO style format.\n",
    "\n",
    "The resulting .csv file contains a list of all the tokens in Book 4 (18,664) including punctuation and special characters. Each token is associated to its reference position (book, chapter, paragraph), the position of the token in the paragraph ('Index' column), the start position of the token in the paragraph at the character level ('Start pos' column), the BIO annotation in Flair, Flair-large and Flair+Splitter with the precision score and the BIO annotation in spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943b4bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "##import Flair NER\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from flair.data import Sentence\n",
    "from flair.nn import Classifier\n",
    "from flair.models import SequenceTagger\n",
    "from flair.splitter import SegtokSentenceSplitter\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3428e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "## open the source HTML page as soup by BeautifulSoup\n",
    "soup = BeautifulSoup(open(\"/Users/u0154817/OneDrive - KU Leuven/Documents/KU Leuven/PhD project 'Greek Spaces in Roman Times'/Data_Extraction/Sources/NH_Eng_ToposText/NH_Eng_1-11.html\", encoding='utf-8'), features=\"lxml\")\n",
    "\n",
    "## get all the paragraphs in Book 4\n",
    "book_4 = soup.find_all(\"p\", id=lambda x: x and x.startswith(\"urn:cts:latinLit:phi0978.phi001:4.\")) ## get all the paragraph starting with the ID phi0978.phi001:4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a624c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_column = []\n",
    "index_column = []\n",
    "token_column = []\n",
    "start_pos_column = []\n",
    "BIO_column = []\n",
    "BIO_precision = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac78f76",
   "metadata": {},
   "source": [
    "# Flair ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e40e47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for paragraph in book_4: ## for each paragraph in Book 4\n",
    "    \n",
    "    p_tag_id = paragraph['id'] ##get the id of the paragraph\n",
    "    print(p_tag_id) ##print the id of the paragraph\n",
    "    text = paragraph.get_text() ## get the text of the paragraph\n",
    "    \n",
    "    reference_column_temp = []\n",
    "    index_column_temp = []\n",
    "    token_column_temp = []\n",
    "    start_pos_column_temp = []\n",
    "    BIO_column_temp = []\n",
    "    BIO_precision_temp = []\n",
    "\n",
    "    ## make a sentence from the text using the Flair Sentence function\n",
    "    sentence = Sentence(text)\n",
    "\n",
    "    ## load the NER tagger ner-large\n",
    "    tagger = Classifier.load('ner')\n",
    "\n",
    "    ## run NER over the sentence\n",
    "    tagger.predict(sentence)\n",
    "\n",
    "    for index, token in enumerate(sentence):\n",
    "        \n",
    "        token_text = token.text ## get the text of the token\n",
    "        start_pos = token.start_position ##get the start position of the token\n",
    "\n",
    "        reference_column_temp.append(p_tag_id)\n",
    "        index_column_temp.append(index)\n",
    "        token_column_temp.append(token_text)\n",
    "        start_pos_column_temp.append(start_pos)\n",
    "        BIO_column_temp.append('O')\n",
    "        BIO_precision_temp.append('-')\n",
    "        \n",
    "    \n",
    "    for entity in sentence.get_spans('ner'): ##obtain span objects of the Named Entities\n",
    "        \n",
    "        entity_label = entity.labels[0].value ##extract the label assigned to the entity\n",
    "        entity_score = entity.labels[0].score ## get the probability score for the type label\n",
    "    \n",
    "        for index,token in enumerate(entity): ##for each token in the entity\n",
    "            start_pos_token = token.start_position ##get the start position of the token in the sentence\n",
    "        \n",
    "            if index == 0: ##if it is the first token in the named entity\n",
    "                entity_label_token = 'B-'+str(entity_label) ##the label starts with B-(eginning)\n",
    "            else :\n",
    "                entity_label_token = 'I-'+str(entity_label) ##the label starts with I-(nside)\n",
    "                    \n",
    "            for i,start_position in enumerate(start_pos_column_temp):\n",
    "                \n",
    "                if int(start_pos_token) == int(start_position):\n",
    "                    BIO_column_temp[i] = entity_label_token\n",
    "                    BIO_precision_temp[i] = entity_score\n",
    "        \n",
    "    reference_column.extend(reference_column_temp)\n",
    "    index_column.extend(index_column_temp)\n",
    "    token_column.extend(token_column_temp)\n",
    "    start_pos_column.extend(start_pos_column_temp)\n",
    "    BIO_column.extend(BIO_column_temp)\n",
    "    BIO_precision.extend(BIO_precision_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74706704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas dataframe\n",
    "\n",
    "data = {\n",
    "    'Reference': reference_column,\n",
    "    'Index': index_column,\n",
    "    'Token': token_column,\n",
    "    'Start_pos': start_pos_column,\n",
    "    'BIO_Flair': BIO_column,\n",
    "    'Precision_Flair': BIO_precision\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13b06ce",
   "metadata": {},
   "source": [
    "# Flair ner-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b4c9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIO_Flair_large_column = []\n",
    "Precision_Flair_large_column = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299e8d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "for paragraph in book_4: ## for each paragraph in Book 4\n",
    "    \n",
    "    p_tag_id = paragraph['id'] ##get the id of the paragraph\n",
    "    print(p_tag_id) ##print the id of the paragraph\n",
    "    text = paragraph.get_text() ## get the text of the paragraph\n",
    "\n",
    "    start_pos_column_temp = []\n",
    "    BIO_Flair_large_column_temp = []\n",
    "    Precision_Flair_large_column_temp = []\n",
    "    \n",
    "    ## make a sentence from the text using the Flair Sentence function\n",
    "    sentence = Sentence(text)\n",
    "\n",
    "    ## load the NER tagger ner-large\n",
    "    tagger = Classifier.load('ner-large')\n",
    "\n",
    "    ## run NER over the sentence\n",
    "    tagger.predict(sentence)\n",
    "    \n",
    "    for index, token in enumerate(sentence):\n",
    "        \n",
    "        start_pos = token.start_position ##get the start position of the token\n",
    "\n",
    "        start_pos_column_temp.append(start_pos)\n",
    "        BIO_Flair_large_column_temp.append('O')\n",
    "        Precision_Flair_large_column_temp.append('-')\n",
    "\n",
    "    for entity in sentence.get_spans('ner'): ##obtain span objects\n",
    "    \n",
    "        entity_label = entity.labels[0].value ##extract the label assigned to the entity\n",
    "        entity_score = entity.labels[0].score ## get the probability score for the type label\n",
    "    \n",
    "        for index,token in enumerate(entity): ##entities can be composed by one or more than one token\n",
    "            start_pos_token = token.start_position ##get the start position of the token in the sentence\n",
    "        \n",
    "            if index == 0: ##if it is the first token in the named entity\n",
    "                entity_label_token = 'B-'+str(entity_label) ##the label starts with B-(eginning)\n",
    "            else :\n",
    "                entity_label_token = 'I-'+str(entity_label) ##the label starts with I-(nside)\n",
    "                    \n",
    "            for i,start_position in enumerate(start_pos_column_temp):\n",
    "            \n",
    "                if int(start_pos_token) == int(start_position):\n",
    "                    BIO_Flair_large_column_temp[i] = entity_label_token\n",
    "                    Precision_Flair_large_column_temp[i] = entity_score\n",
    "    \n",
    "    BIO_Flair_large_column.extend(BIO_Flair_large_column_temp)\n",
    "    Precision_Flair_large_column.extend(Precision_Flair_large_column_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d532fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BIO_Flair-large'] = BIO_Flair_large_column\n",
    "df['Precision_Flair-large'] = Precision_Flair_large_column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f434b061",
   "metadata": {},
   "source": [
    "# Flair ner-large + SegtokSentenceSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d4c1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##initialize sentence splitter\n",
    "splitter = SegtokSentenceSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f37b7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIO_Flair_splitter_column = []\n",
    "Precision_Flair_splitter_column = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c79148",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for paragraph in book_4: ## for each paragraph in Book 4\n",
    "    \n",
    "    p_tag_id = paragraph['id'] ##get the id of the paragraph\n",
    "    print(p_tag_id) ##print the id of the paragraph\n",
    "    text = paragraph.get_text() ## get the text of the paragraph\n",
    "\n",
    "    ##use splitter to split text into list of sentences\n",
    "    sentences = splitter.split(text)\n",
    "    \n",
    "    tagger = Classifier.load('ner-large')\n",
    "    tagger.predict(sentences)\n",
    "\n",
    "    for index,sentence in enumerate(sentences):\n",
    "        \n",
    "        if len(sentence) > 0:\n",
    "                    \n",
    "            start_pos_splitter_column = []\n",
    "            BIO_Flair_splitter_column_temp = []\n",
    "            Precision_Flair_splitter_temp = []\n",
    "        \n",
    "            for token in sentence: ##for each token in the sentence\n",
    "                \n",
    "                start_pos_splitter = str(token.start_position) ##get the start position of the token in the sentence\n",
    "            \n",
    "                start_pos_splitter_column.append(start_pos_splitter) ##append the start position in the splitted sentences\n",
    "                BIO_Flair_splitter_column_temp.append('O')\n",
    "                Precision_Flair_splitter_temp.append('-')\n",
    "                        \n",
    "            for entity in sentence.get_spans('ner'):\n",
    "        \n",
    "                entity_label = entity.labels[0].value ##extract the label assigned to the entity\n",
    "                entity_score = entity.labels[0].score ## get the probability score for the type label\n",
    "    \n",
    "                for index1,token in enumerate(entity): ##entities can be composed by one or more than one token\n",
    "            \n",
    "                    start_pos_token = str(token.start_position) ##get the start position of the token in the sentence\n",
    "        \n",
    "                    if index1 == 0: ##if it is the first token in the named entity\n",
    "                        entity_label_token = 'B-'+str(entity_label) ##the label starts with B-(eginning)\n",
    "                    else :\n",
    "                        entity_label_token = 'I-'+str(entity_label) ##the label starts with I-(nside)\n",
    "                    \n",
    "                    for index2,start_position in enumerate(start_pos_splitter_column):\n",
    "            \n",
    "                        if str(start_pos_token) == str(start_position):\n",
    "                            BIO_Flair_splitter_column_temp[index2] = entity_label_token\n",
    "                            Precision_Flair_splitter_temp[index2] = entity_score\n",
    "    \n",
    "            BIO_Flair_splitter_column.extend(BIO_Flair_splitter_column_temp)\n",
    "            Precision_Flair_splitter_column.extend(Precision_Flair_splitter_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7a2864",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Precision_Flair_splitter_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dc43c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BIO_Flair_Splitter'] = BIO_Flair_splitter_column\n",
    "df['Precision_Flair_Splitter'] = Precision_Flair_splitter_column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8045d5d",
   "metadata": {},
   "source": [
    "# spaCy-md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e3df79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BIO_spaCy-md'] = 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82476922",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_spaCy = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1837d985",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for paragraph in book_4: ## for each paragraph in Book 4\n",
    "    \n",
    "    p_tag_id = paragraph['id'] ##get the id of the paragraph\n",
    "    print(p_tag_id) ##print the id of the paragraph\n",
    "    text = paragraph.get_text() ## get the text of the paragraph\n",
    "\n",
    "    processed_text = nlp_spaCy(text)\n",
    "    \n",
    "    for entity in processed_text: \n",
    "        \n",
    "        if entity.ent_type_:\n",
    "            \n",
    "            entity_label_token = str(entity.ent_iob_)+'-'+entity.ent_type_\n",
    "            start_pos_token = entity.idx ##get the start position of the entity in the paragraph\n",
    "            paragraph_start_pos = str(p_tag_id)+'.'+str(start_pos_token)\n",
    "    \n",
    "            for i, reference in enumerate(df['Reference']):\n",
    "                \n",
    "                reference_position = str(reference)+'.'+str(df['Start_pos'][i])\n",
    "                if paragraph_start_pos == reference_position:\n",
    "                    \n",
    "                    df['BIO_spaCy-md'][i] = entity_label_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6726bbd1",
   "metadata": {},
   "source": [
    "# spaCy-trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9c6b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BIO_spaCy-trf'] = 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ebcdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_spaCy = spacy.load(\"en_core_web_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade224de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for paragraph in book_4: ## for each paragraph in Book 4\n",
    "    \n",
    "    p_tag_id = paragraph['id'] ##get the id of the paragraph\n",
    "    print(p_tag_id) ##print the id of the paragraph\n",
    "    text = paragraph.get_text() ## get the text of the paragraph\n",
    "\n",
    "    processed_text = nlp_spaCy(text)\n",
    "    \n",
    "    for entity in processed_text: \n",
    "        \n",
    "        if entity.ent_type_:\n",
    "            \n",
    "            entity_label_token = str(entity.ent_iob_)+'-'+entity.ent_type_\n",
    "            start_pos_token = entity.idx ##get the start position of the entity in the paragraph\n",
    "            paragraph_start_pos = str(p_tag_id)+'.'+str(start_pos_token)\n",
    "    \n",
    "            for i, reference in enumerate(df['Reference']):\n",
    "                \n",
    "                reference_position = str(reference)+'.'+str(df['Start_pos'][i])\n",
    "                if paragraph_start_pos == reference_position:\n",
    "                    \n",
    "                    df['BIO_spaCy-trf'][i] = entity_label_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbddc9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"BIO_NER_Flair_spaCy.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
