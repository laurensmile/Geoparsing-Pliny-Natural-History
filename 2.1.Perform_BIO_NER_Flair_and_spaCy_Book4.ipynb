{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d74066e",
   "metadata": {},
   "source": [
    "# Perform NER on Book 4 (BIO format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b575ad8a",
   "metadata": {},
   "source": [
    "The notebook contains the code to perform Flair NER and spaCy NER on Book 4 and structure the output in the BIO style format.\n",
    "\n",
    "We used two different NER systems:\n",
    "\n",
    "- Flair (https://flairnlp.github.io/docs/tutorial-basics/tagging-entities)\n",
    "- SpaCy (https://spacy.io/models/en)\n",
    "\n",
    "Each system was tested according to different parameters. More specifically, we compared:\n",
    "\n",
    "- Flair ner\n",
    "- Flair ner-large\n",
    "- Flair ner-large in combination with SegtokSentenceSplitter\n",
    "- en_core_web_md\n",
    "- en_core_web_trf\n",
    "\n",
    "The resulting .csv file contains a list of all the tokens in Book 4 (18,664) including punctuation and special characters. Each token is associated to its reference position (book, chapter, paragraph), the position of the token in the paragraph ('Index' column), the start position of the token in the paragraph at the character level ('Start pos' column), the BIO annotation in Flair, Flair-large and Flair+Splitter with the precision score and the BIO annotation in spaCy.\n",
    "\n",
    "For an introduction to the principles of the BIO style annotation see: https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943b4bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "## import Flair\n",
    "from flair.data import Sentence\n",
    "from flair.nn import Classifier\n",
    "from flair.models import SequenceTagger\n",
    "from flair.splitter import SegtokSentenceSplitter\n",
    "\n",
    "## import spaCy\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3428e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "## open the source HTML page as soup by BeautifulSoup\n",
    "soup = BeautifulSoup(open(\"/Users/u0154817/OneDrive - KU Leuven/Documents/KU Leuven/PhD project 'Greek Spaces in Roman Times'/Data_Extraction/Sources/NH_Eng_ToposText/NH_Eng_1-11.html\", encoding='utf-8'), features=\"lxml\")\n",
    "\n",
    "## get all the paragraphs in Book 4\n",
    "book_4 = soup.find_all(\"p\", id=lambda x: x and x.startswith(\"urn:cts:latinLit:phi0978.phi001:4.\")) ## get all the paragraph starting with the ID phi0978.phi001:4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a624c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_column = []\n",
    "index_column = []\n",
    "token_column = []\n",
    "start_pos_column = []\n",
    "BIO_column = []\n",
    "BIO_precision = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac78f76",
   "metadata": {},
   "source": [
    "# Flair ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e40e47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for paragraph in book_4: ## for each paragraph in Book 4\n",
    "    \n",
    "    p_tag_id = paragraph['id'] ## get the id of the paragraph\n",
    "    print(p_tag_id) ## print the id of the paragraph\n",
    "    text = paragraph.get_text() ## get the text of the paragraph\n",
    "    \n",
    "    ## create temporary lists\n",
    "    reference_column_temp = []\n",
    "    index_column_temp = []\n",
    "    token_column_temp = []\n",
    "    start_pos_column_temp = []\n",
    "    BIO_column_temp = []\n",
    "    BIO_precision_temp = []\n",
    "\n",
    "    ## make a Flair Sentence from the text of the paragraph using the Flair Sentence function\n",
    "    sentence = Sentence(text)\n",
    "\n",
    "    ## load the NER tagger ner\n",
    "    tagger = Classifier.load('ner')\n",
    "\n",
    "    ## run NER over the Sentence\n",
    "    tagger.predict(sentence)\n",
    "\n",
    "    for index, token in enumerate(sentence): ## for each token in the Sentence\n",
    "        \n",
    "        token_text = token.text ## get the text of the token\n",
    "        start_pos = token.start_position ## get the start position of the token\n",
    "\n",
    "        reference_column_temp.append(p_tag_id) ## append the id of the paragraph\n",
    "        index_column_temp.append(index) ## append the index of the token\n",
    "        token_column_temp.append(token_text) ## append the token\n",
    "        start_pos_column_temp.append(start_pos) ## append the start position of the token\n",
    "        BIO_column_temp.append('O') ## append a temporary O label\n",
    "        BIO_precision_temp.append('-') ## append a temporary - value\n",
    "        \n",
    "    \n",
    "    for entity in sentence.get_spans('ner'): ## for each NER Entity in the Sentence\n",
    "        \n",
    "        entity_label = entity.labels[0].value ## extract the label assigned to the Entity\n",
    "        entity_score = entity.labels[0].score ## get the probability score for the label\n",
    "    \n",
    "        for index,token in enumerate(entity): ## for each token in the Entity\n",
    "            start_pos_token = token.start_position ## get the start position of the token\n",
    "        \n",
    "            if index == 0: ## if it is the first token in the Entity\n",
    "                entity_label_token = 'B-'+str(entity_label) ## the label starts with B-(eginning)\n",
    "            else : ## if not\n",
    "                entity_label_token = 'I-'+str(entity_label) ## the label starts with I-(nside)\n",
    "                    \n",
    "            for i,start_position in enumerate(start_pos_column_temp): ## for each start position in the list created above\n",
    "                \n",
    "                if int(start_pos_token) == int(start_position): ## find the correspondent position of the token\n",
    "                    BIO_column_temp[i] = entity_label_token ## update the BIO column\n",
    "                    BIO_precision_temp[i] = entity_score ## update the Precision column\n",
    "        \n",
    "    reference_column.extend(reference_column_temp)\n",
    "    index_column.extend(index_column_temp)\n",
    "    token_column.extend(token_column_temp)\n",
    "    start_pos_column.extend(start_pos_column_temp)\n",
    "    BIO_column.extend(BIO_column_temp)\n",
    "    BIO_precision.extend(BIO_precision_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74706704",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a pandas dataframe\n",
    "\n",
    "data = {\n",
    "    'Reference': reference_column,\n",
    "    'Index': index_column,\n",
    "    'Token': token_column,\n",
    "    'Start_pos': start_pos_column,\n",
    "    'BIO_Flair': BIO_column,\n",
    "    'Precision_Flair': BIO_precision\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13b06ce",
   "metadata": {},
   "source": [
    "# Flair ner-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b4c9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIO_Flair_large_column = []\n",
    "Precision_Flair_large_column = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299e8d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "for paragraph in book_4: \n",
    "    \n",
    "    p_tag_id = paragraph['id'] \n",
    "    print(p_tag_id) \n",
    "    text = paragraph.get_text() \n",
    "\n",
    "    start_pos_column_temp = []\n",
    "    BIO_Flair_large_column_temp = []\n",
    "    Precision_Flair_large_column_temp = []\n",
    "    \n",
    "    sentence = Sentence(text)\n",
    "\n",
    "    ## load the NER tagger ner-large\n",
    "    tagger = Classifier.load('ner-large')\n",
    "\n",
    "    tagger.predict(sentence)\n",
    "    \n",
    "    for index, token in enumerate(sentence):\n",
    "        \n",
    "        start_pos = token.start_position \n",
    "\n",
    "        start_pos_column_temp.append(start_pos)\n",
    "        BIO_Flair_large_column_temp.append('O')\n",
    "        Precision_Flair_large_column_temp.append('-')\n",
    "\n",
    "    for entity in sentence.get_spans('ner'):\n",
    "    \n",
    "        entity_label = entity.labels[0].value \n",
    "        entity_score = entity.labels[0].score\n",
    "    \n",
    "        for index,token in enumerate(entity):\n",
    "            start_pos_token = token.start_position\n",
    "        \n",
    "            if index == 0: \n",
    "                entity_label_token = 'B-'+str(entity_label)\n",
    "            else :\n",
    "                entity_label_token = 'I-'+str(entity_label) \n",
    "                    \n",
    "            for i,start_position in enumerate(start_pos_column_temp):\n",
    "            \n",
    "                if int(start_pos_token) == int(start_position):\n",
    "                    BIO_Flair_large_column_temp[i] = entity_label_token\n",
    "                    Precision_Flair_large_column_temp[i] = entity_score\n",
    "    \n",
    "    BIO_Flair_large_column.extend(BIO_Flair_large_column_temp)\n",
    "    Precision_Flair_large_column.extend(Precision_Flair_large_column_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d532fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BIO_Flair-large'] = BIO_Flair_large_column\n",
    "df['Precision_Flair-large'] = Precision_Flair_large_column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f434b061",
   "metadata": {},
   "source": [
    "# Flair ner-large + SegtokSentenceSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d4c1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialize sentence splitter\n",
    "splitter = SegtokSentenceSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f37b7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIO_Flair_splitter_column = []\n",
    "Precision_Flair_splitter_column = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c79148",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for paragraph in book_4: ## for each paragraph in Book 4\n",
    "    \n",
    "    p_tag_id = paragraph['id'] ## get the id of the paragraph\n",
    "    print(p_tag_id) ## print the id of the paragraph\n",
    "    text = paragraph.get_text() ## get the text of the paragraph\n",
    "\n",
    "    ## use Splitter to split the text into a list of Sentences\n",
    "    sentences = splitter.split(text)\n",
    "    \n",
    "    ## load the NER tagger ner-large\n",
    "    tagger = Classifier.load('ner-large')\n",
    "    tagger.predict(sentences)\n",
    "\n",
    "    for index,sentence in enumerate(sentences): ## for each Sentence in Sentences\n",
    "        \n",
    "        if len(sentence) > 0: ## if the Sentence exists\n",
    "                    \n",
    "            start_pos_splitter_column = []\n",
    "            BIO_Flair_splitter_column_temp = []\n",
    "            Precision_Flair_splitter_temp = []\n",
    "        \n",
    "            for token in sentence: ## for each token in the splitted Sentence\n",
    "                \n",
    "                start_pos_splitter = str(token.start_position) \n",
    "            \n",
    "                start_pos_splitter_column.append(start_pos_splitter) \n",
    "                BIO_Flair_splitter_column_temp.append('O') \n",
    "                Precision_Flair_splitter_temp.append('-') \n",
    "                        \n",
    "            for entity in sentence.get_spans('ner'): ## for each NER Entity in the splitted Sentence\n",
    "        \n",
    "                entity_label = entity.labels[0].value \n",
    "                entity_score = entity.labels[0].score \n",
    "    \n",
    "                for index1,token in enumerate(entity):\n",
    "            \n",
    "                    start_pos_token = str(token.start_position) \n",
    "        \n",
    "                    if index1 == 0: \n",
    "                        entity_label_token = 'B-'+str(entity_label) \n",
    "                    else :\n",
    "                        entity_label_token = 'I-'+str(entity_label)\n",
    "                    \n",
    "                    for index2,start_position in enumerate(start_pos_splitter_column):\n",
    "            \n",
    "                        if str(start_pos_token) == str(start_position):\n",
    "                            BIO_Flair_splitter_column_temp[index2] = entity_label_token\n",
    "                            Precision_Flair_splitter_temp[index2] = entity_score\n",
    "    \n",
    "            BIO_Flair_splitter_column.extend(BIO_Flair_splitter_column_temp)\n",
    "            Precision_Flair_splitter_column.extend(Precision_Flair_splitter_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dc43c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BIO_Flair_Splitter'] = BIO_Flair_splitter_column\n",
    "df['Precision_Flair_Splitter'] = Precision_Flair_splitter_column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8045d5d",
   "metadata": {},
   "source": [
    "# spaCy-md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e3df79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BIO_spaCy-md'] = 'O' ## create a column with temporary O label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82476922",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the NER model\n",
    "nlp_spaCy = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3815e52",
   "metadata": {},
   "source": [
    "We observed that the nlp_spaCy tokenization is slighlty different from the Flair tokenization and the list of tokens obtained from spaCy does not align with the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1837d985",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for paragraph in book_4: ## for each paragraph in Book 4\n",
    "    \n",
    "    p_tag_id = paragraph['id'] ## get the id of the paragraph\n",
    "    print(p_tag_id) ## print the id of the paragraph\n",
    "    text = paragraph.get_text() ## get the text of the paragraph\n",
    "\n",
    "    processed_text = nlp_spaCy(text) ## run NER over the paragraph\n",
    "    \n",
    "    for token in processed_text: ## for each token\n",
    "        \n",
    "        if token.ent_type_: ## if the token has an Entity label\n",
    "            \n",
    "            token = entity ## the token is an Entity\n",
    "            \n",
    "            entity_label_token = str(entity.ent_iob_)+'-'+entity.ent_type_ ## extract the label assigned to the Entity\n",
    "            start_pos_token = entity.idx ## get the start position of the Entity\n",
    "            paragraph_start_pos = str(p_tag_id)+'.'+str(start_pos_token) ## get the reference+start position\n",
    "    \n",
    "            for i, reference in enumerate(df['Reference']): ## for each token in the dataframe\n",
    "                \n",
    "                reference_position = str(reference)+'.'+str(df['Start_pos'][i]) ## get the reference+start position\n",
    "                if paragraph_start_pos == reference_position: ## if it is the same\n",
    "                    \n",
    "                    df['BIO_spaCy-md'][i] = entity_label_token ## update the label column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6726bbd1",
   "metadata": {},
   "source": [
    "# spaCy-trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9c6b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BIO_spaCy-trf'] = 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ebcdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the NER model\n",
    "nlp_spaCy = spacy.load(\"en_core_web_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade224de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for paragraph in book_4:\n",
    "    \n",
    "    p_tag_id = paragraph['id']\n",
    "    print(p_tag_id)\n",
    "    text = paragraph.get_text()\n",
    "\n",
    "    processed_text = nlp_spaCy(text)\n",
    "    \n",
    "    for token in processed_text: \n",
    "        \n",
    "        if token.ent_type_:\n",
    "            \n",
    "            token = entity\n",
    "            \n",
    "            entity_label_token = str(entity.ent_iob_)+'-'+entity.ent_type_\n",
    "            start_pos_token = entity.idx \n",
    "            paragraph_start_pos = str(p_tag_id)+'.'+str(start_pos_token)\n",
    "    \n",
    "            for i, reference in enumerate(df['Reference']):\n",
    "                \n",
    "                reference_position = str(reference)+'.'+str(df['Start_pos'][i])\n",
    "                if paragraph_start_pos == reference_position:\n",
    "                    \n",
    "                    df['BIO_spaCy-trf'][i] = entity_label_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbddc9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"BIO_NER_Flair_spaCy.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
