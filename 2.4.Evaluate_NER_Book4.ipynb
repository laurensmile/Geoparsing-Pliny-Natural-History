{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d35e2ac4",
   "metadata": {},
   "source": [
    "# Evaluate NER on Book 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b759887",
   "metadata": {},
   "source": [
    "To assess the quality of NER annotation in Book 4, Precision, Recall, and F1 Score measurements were used against a Gold Standard. Among the NER systems we tested, Flair ner-large emerged as the top performer, achieving a high-quality annotation with an F1 Score of 0.945, along with strong Precision (0.952) and Recall (0.938) values.\n",
    "\n",
    "However, Flair ner had a somewhat lower Recall (0.637), indicating instances where entities were missed. On a positive note, the spaCy-trf model also delivered promising results (Precision: 0.938, Recall: 0.938, F1 Score: 0.938).\n",
    "\n",
    "During the calculation of True Positives, False Negatives, and False Positives, we took into account the possibility of partial matches between multi-word entities due to variations in entity boundaries. To handle this, we chose to evaluate annotations on a named-entity level rather than a token-level basis. For this compute see also: https://github.com/chakki-works/seqeval/tree/master.\n",
    "\n",
    "It's worth pointing out that Flair ner-large failed to identify 119 place entities. While it did manage to detect 115 of these entities, they were not correctly labeled as places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12c466c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bf09a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## open the Gold Standard of Book 4 (18,664 rows)\n",
    "GoldStandard_Book4 = pd.read_excel(\"/Users/u0154817/OneDrive - KU Leuven/Documents/KU Leuven/PhD project 'Greek Spaces in Roman Times'/Data_Extraction/Outputs/1.4.GoldStandard_Book4.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2b249b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18664"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(GoldStandard_Book4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ae4b1ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## open the output of Flair NER (18,664 rows)\n",
    "NERs_Book4 = pd.read_csv(\"/Users/u0154817/OneDrive - KU Leuven/Documents/KU Leuven/PhD project 'Greek Spaces in Roman Times'/Data_Extraction/Outputs/2.2.BIO_NER_Flair_spaCy_Book4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6547c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18664"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(NERs_Book4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41dee2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## append the Gold Standard to the dataset of the NER outputs\n",
    "NERs_Book4['Manual_Annotation'] = GoldStandard_Book4['Manual_Annotation']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc159f8f",
   "metadata": {},
   "source": [
    "# Flair ner-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84d4900a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a copy of the Flair ner-large column\n",
    "NERs_Book4['BIO_Flair-large_copy'] = NERs_Book4['BIO_Flair-large']\n",
    "\n",
    "## the function trasnform all the annotations not including LOC into O\n",
    "def update_values(value):\n",
    "    if 'LOC' not in value:\n",
    "        return 'O'\n",
    "    return value\n",
    "\n",
    "NERs_Book4['BIO_Flair-large_copy'] = NERs_Book4['BIO_Flair-large_copy'].apply(update_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8688009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'B-LOC', 'I-LOC'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NERs_Book4['BIO_Flair-large_copy'].unique() ## the new column contains only O, B-LOC and I-LOC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce619b0a",
   "metadata": {},
   "source": [
    "**Compute True Positive and False Negatives including partial matches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73d147ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "True_Positives = [] ## create a list of true positives\n",
    "False_Negatives = [] ## create a list of false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "496eb20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, manual_annotation in enumerate(NERs_Book4['Manual_Annotation']): ## for each token in the Gold Standard\n",
    "        \n",
    "    if manual_annotation == 'B-LOC': ## for each B-LOC entity in the Gold Standard\n",
    "        \n",
    "        ## create a tuple containing the reference and start position\n",
    "        reference_startpos = (NERs_Book4['Reference'][index], NERs_Book4['Start_pos'][index])\n",
    "        \n",
    "        if len(NERs_Book4['BIO_Flair-large_copy'][index]) > 1: ## if the NER system predicted a LOC entity for the token\n",
    "            True_Positives.append(reference_startpos) ## it is a true positive\n",
    "            \n",
    "        else: ## if the NER system did not predict a LOC entity for the token\n",
    "            \n",
    "            if NERs_Book4['Manual_Annotation'][index+1] != 'I-LOC': ## if B-LOC is not followed by I-LOC\n",
    "                False_Negatives.append(reference_startpos) ## it is a false negative\n",
    "            \n",
    "            else: ## if B-LOC is followed by I-LOC\n",
    "                \n",
    "                flag = False\n",
    "                \n",
    "                for n in range(1,100):\n",
    "                    \n",
    "                    if NERs_Book4['Manual_Annotation'][index+n] == 'I-LOC': ## inside the multi-word LOC entity\n",
    "                        \n",
    "                        if len(NERs_Book4['BIO_Flair-large_copy'][index+n]) > 1: ## the NER system predicted a LOC entity\n",
    "                            True_Positives.append((NERs_Book4['Reference'][index+n], NERs_Book4['Start_pos'][index+n])) ## it is a true positive\n",
    "                            flag = True\n",
    "                            break\n",
    "                            \n",
    "                    else: break\n",
    "                        \n",
    "                if flag == False: ## no entity was predicted in the span\n",
    "                    False_Negatives.append(reference_startpos) ## it is a false negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca41e66",
   "metadata": {},
   "source": [
    "Flair ner-large contains 1,811 True Positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63c32b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1811"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(True_Positives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f28da6",
   "metadata": {},
   "source": [
    "Flair ner-large contains 119 False Negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7821f1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(False_Negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8d456d",
   "metadata": {},
   "source": [
    "**Compute False Positives**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "653de5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "False_Positives = [] ## create a list of false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8b3fe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, Flair_nerlarge_annotation in enumerate(NERs_Book4['BIO_Flair-large_copy']):\n",
    "        \n",
    "    if Flair_nerlarge_annotation == 'B-LOC': ## for each B-LOC Flair annotation\n",
    "        \n",
    "        ## create a tuple containing the reference and start position\n",
    "        reference_startpos = (NERs_Book4['Reference'][index], NERs_Book4['Start_pos'][index])\n",
    "        \n",
    "        if len(NERs_Book4['Manual_Annotation'][index]) == 1: ## if the Gold Standard does not contain an entity\n",
    "            \n",
    "            if NERs_Book4['BIO_Flair-large_copy'][index+1] != 'I-LOC': ## if B-LOC is not followed by I-LOC\n",
    "                False_Positives.append(reference_startpos) ## it is a false positive\n",
    "        \n",
    "        else: ## if B-LOC is followed by I-LOC\n",
    "            \n",
    "            flag = False\n",
    "            \n",
    "            for n in range(1,100):\n",
    "                \n",
    "                if NERs_Book4['BIO_Flair-large_copy'][index+1] == 'I-LOC': ## inside the multi-word LOC annotation\n",
    "                    \n",
    "                    if len(NERs_Book4['Manual_Annotation'][index+n]) > 1: ## the Gold Standard contains an entity\n",
    "                        flag = True\n",
    "                        break\n",
    "                        \n",
    "                else: break\n",
    "                        \n",
    "                if flag == False:\n",
    "                    False_Positives.append(reference_startpos) ## it is a false positive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98d278d",
   "metadata": {},
   "source": [
    "Flair ner-large contains 91 False Positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46fba2e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(False_Positives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0669cb6c",
   "metadata": {},
   "source": [
    "Flair ner-large had a Precision of 0.952."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8550ca2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9521556256572029"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## calculate Precision\n",
    "\n",
    "Precision = len(True_Positives) / (len(True_Positives) + len(False_Positives))\n",
    "Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb92c32",
   "metadata": {},
   "source": [
    "Flair ner-large had a Recall of 0.938."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4baff854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9383419689119171"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## calculate Recall\n",
    "\n",
    "Recall = len(True_Positives) / (len(True_Positives) + len(False_Negatives))\n",
    "Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c594ced2",
   "metadata": {},
   "source": [
    "Flair ner-large had a F1 Score of 0.945."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a269f91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9451983298538622"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## calculate F1 Score\n",
    "\n",
    "F1 = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "F1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41115579",
   "metadata": {},
   "source": [
    "**Compute the cases in which NER predicts a named entity but assigns the label wrong**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "294ba968",
   "metadata": {},
   "outputs": [],
   "source": [
    "Incorrect_Labels = []\n",
    "\n",
    "for index, manual_annotation in enumerate(NERs_Book4['Manual_Annotation']): ## for each token in the Gold Standard\n",
    "        \n",
    "    if manual_annotation == 'B-LOC': ## for each B-LOC entity in the Gold Standard\n",
    "        \n",
    "        ## create a tuple containing the reference and start position\n",
    "        reference_startpos = (NERs_Book4['Reference'][index], NERs_Book4['Start_pos'][index])\n",
    "        \n",
    "        if len(NERs_Book4['BIO_Flair-large'][index]) > 1: ## if an entity is predicted for the token            \n",
    "            if 'LOC' not in str(NERs_Book4['BIO_Flair-large'][index]): ## if the entity label is not LOC \n",
    "                Incorrect_Labels.append(reference_startpos) ## it is an incorrect entity label\n",
    "            \n",
    "        if len(NERs_Book4['BIO_Flair-large'][index]) == 1: ## if no entity is predicted for the token \n",
    "            \n",
    "            if NERs_Book4['Manual_Annotation'][index+1] == 'I-LOC':\n",
    "                \n",
    "                flag = False\n",
    "                \n",
    "                for n in range(1,100): ## for any natural number\n",
    "                    \n",
    "                    if NERs_Book4['Manual_Annotation'][index+n] == 'I-LOC':\n",
    "                        \n",
    "                        if len(NERs_Book4['BIO_Flair-large'][index+n]) > 1: ## if an entity is predicted for the token\n",
    "                            \n",
    "                            if 'LOC' not in str(NERs_Book4['BIO_Flair-large'][index+n]): ## if the entity is not annotated as LOC\n",
    "                                if str(NERs_Book4['BIO_Flair-large'][index+n]).startswith('B-'):\n",
    "                                    Incorrect_Labels.append((NERs_Book4['Reference'][index+n], NERs_Book4['Start_pos'][index+n])) ## it is an incorrect entity labelflag = True\n",
    "                                \n",
    "                    else: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f8e3952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Incorrect_Labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e3090b",
   "metadata": {},
   "source": [
    "# spaCy trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d849dd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "NERs_Book4['BIO_spaCy-trf_copy'] = NERs_Book4['BIO_spaCy-trf']\n",
    "\n",
    "## the function trasnform all the GPE annotations into LOC annotations\n",
    "def update_labels(label):\n",
    "    if 'B-GPE' in label:\n",
    "        return 'B-LOC'\n",
    "    if 'I-GPE' in label:\n",
    "        return 'I-LOC'\n",
    "    return label\n",
    "\n",
    "NERs_Book4['BIO_spaCy-trf_copy'] = NERs_Book4['BIO_spaCy-trf_copy'].apply(update_labels)\n",
    "NERs_Book4['BIO_spaCy-trf_copy'] = NERs_Book4['BIO_spaCy-trf_copy'].apply(update_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3d17ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'B-LOC', 'I-LOC'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NERs_Book4['BIO_spaCy-trf_copy'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
