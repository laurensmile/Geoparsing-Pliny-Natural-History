{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b33a27bc",
   "metadata": {},
   "source": [
    "# Extract ToposText Annotations in Book 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a238b8d5",
   "metadata": {},
   "source": [
    "In order to evaluate the quality of the ToposText annotation, we extracted all the annotations in Book 4 including places, persons, and ethnics. For each annotation, we extracted its position (book, chapter, paragraph), the textual content of the tag (ie., Rome), the class label (if present, ie. 'place'), the start and end position of the word in the paragraph, and the corresponding ToposText ID (if present).\n",
    "\n",
    "The position of the word in the paragraph is calculated starting from the very beginning of the paragraph. Please notice that in ToposText each paragraph begins with the ID of the paragraph (for instance, § 4.1.1 EPIRUS: ...). Punctuation was not removed.\n",
    "\n",
    "To extract the start position of the tagged word, we started from the HTML version of the text containing the tags. Then, each paragraph was cleaned removing the p tag (tag of the paragraph), the b tag (tag of the paragraph ID), and the content of the a tags (tags of places, people, ethnics). We substituted the < a > tag with a special character (+) to mark the following word as a 'tagged word'. The position of the special character (+) is the start position of the tagged word minus the number of all the special characters preceding the tagged word present in the paragraph. At the end of the process, we obtained a list of all the start positions of tagged words.\n",
    "\n",
    "Splitting the processes of (1) start position extraction and (2) tagged word extraction was necessary to overcome some difficulties we faced in extracting the start position of words in a tagged text in which some of the tagged words occur more than once.\n",
    "\n",
    "The ToposText IDs are annotated in two different ways. In some tags, the ToposText ID is in the \"about\" element. In other cases, it is in the \"href\" element.\n",
    "\n",
    "In total, 1,888 annotations were present in Book 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d126e2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d10e925",
   "metadata": {},
   "source": [
    "# Extraction of Start Positions of all the Tagged Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f585d0dc",
   "metadata": {},
   "source": [
    "The next cell contains the code to extract the start and end position of a word between tags in an HTML source page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fcca0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "§ 4.37.1  THE GENERAL MEASUREMENT OF EUROPE: Having thus made the circuit of Europe, we must now give the complete measurement of it, in order that those who wish to be acquainted with this subject may not feel themselves at a loss. +Artemidorus and +Isidorus have given its length, from the +Tanais to +Gades, as 8214 miles. +Polybius in his writings has stated the breadth of Europe, in a line from +Italy to the ocean, to be 1150 miles. But, even in his day, its magnitude was but little known. The distance of +Italy, as we have previously stated, as far as the +Alps, is 1120 miles, from which, through +Lugdunum to the +British port of the +Morini, the direction which +Polybius seems to follow, is 1168 miles. But the better ascertained, though greater length, is that taken from the +Alps through the Camp of the Legions in +Germany, in a north-westerly direction, to the mouth of the +Rhine, being 1543 miles. We shall now have to speak of Africa and +Asia. \n",
      "[233, 249, 290, 300, 322, 396, 508, 559, 600, 616, 636, 664, 779, 819, 879, 945]\n"
     ]
    }
   ],
   "source": [
    "## open the source HTML page as soup by BeautifulSoup\n",
    "soup = BeautifulSoup(open(\"/Users/u0154817/OneDrive - KU Leuven/Documents/KU Leuven/PhD project 'Greek Spaces in Roman Times'/Data_Extraction/Sources/NH_Eng_ToposText/NH_Eng_1-11.html\", encoding='utf-8'), features=\"lxml\")\n",
    "\n",
    "## get all the paragraphs in Book 4\n",
    "Book_4 = soup.find_all(\"p\", id=lambda x: x and x.startswith(\"urn:cts:latinLit:phi0978.phi001:4.\")) ## get all the paragraph starting with the ID phi0978.phi001:4.\n",
    "\n",
    "## create a list of the start positions of all the tagged words in Book 4\n",
    "Start_Positions_Annotations_Book4 = []\n",
    "\n",
    "for Paragraph in Book_4: ## for each paragraph in Book 4\n",
    "    \n",
    "    Paragraph=str(Paragraph) ## convert the paragraph to a string\n",
    "    \n",
    "    ## clean the text\n",
    "    Clean_text = re.sub('<p[^>]*>', '', Paragraph) ## remove the p tag\n",
    "    Clean_text = re.sub('</p>', '', Clean_text)\n",
    "\n",
    "    Clean_text = re.sub('<b>', '', Clean_text) ## remove the b tag\n",
    "    Clean_text = re.sub('</b>', '', Clean_text)\n",
    "    \n",
    "    Clean_text = re.sub('</a>', '', Clean_text) ## remove the </a> tag\n",
    "    Clean_text = re.sub('<a[^>]*>', '+', Clean_text) ## substitute the head of the <a> tag with the special character +\n",
    "    \n",
    "    List_of_Start_Positions = [] ## list of the start positions of tagged words in the paragraph\n",
    "    List_of_Special_Char_Seen = 0 ## list of the number of special characters (+) already seen\n",
    "    \n",
    "    for i, Char in enumerate(Clean_text): ## for each character in the paragraph\n",
    "        if Char == \"+\" : ## if the character is the special character +\n",
    "            List_of_Start_Positions.append(i - List_of_Special_Char_Seen) ## the start position of the following tagged word is the position of the special character minus the number of all the special characters alreadty seen\n",
    "            List_of_Special_Char_Seen += 1 ## add +1 to the sum of the special characters already seen\n",
    "            \n",
    "    Start_Positions_Annotations_Book4.extend(List_of_Start_Positions) ## append the list of start position\n",
    "    \n",
    "print(Clean_text) ## show the cleansed text of the last paragraph\n",
    "print(List_of_Start_Positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7afad78",
   "metadata": {},
   "source": [
    "In total, 1,888 start positions of tagged words were extracted from Book 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a2efbda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1888"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Start_Positions_Annotations_Book4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1092cf85",
   "metadata": {},
   "source": [
    "# 1.1.2 Extract all the Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0ddd49",
   "metadata": {},
   "source": [
    "The next cell contains the code to extract tagged words from a ToposText source page and create a CSV file with the extracted information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "198fd965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urn:cts:latinLit:phi0978.phi001:4.37.1 Asia None 945 949 None https://topostext.org/people/15213\n"
     ]
    }
   ],
   "source": [
    "## open the source HTML page as soup by BeautifulSoup\n",
    "soup = BeautifulSoup(open(\"/Users/u0154817/OneDrive - KU Leuven/Documents/KU Leuven/PhD project 'Greek Spaces in Roman Times'/Data_Extraction/Sources/NH_Eng_ToposText/NH_Eng_1-11.html\", encoding='utf-8'), features=\"lxml\")\n",
    "\n",
    "## write the new csv file\n",
    "f = csv.writer(open(\"1.1.ToposText_Annotations_Book_4_TEMP.csv\", \"w\", newline=''))\n",
    "## define column headers in the csv file\n",
    "f.writerow([\"Reference\", \"Tagged Entity\", \"Class\", \"Start position\", \"End position\", \"ToposText ID\", \"Temporary_ToposTextID_href\"])\n",
    "\n",
    "## get all the paragraphs in Book 4\n",
    "Book_4 = soup.find_all(\"p\", id=lambda x: x and x.startswith(\"urn:cts:latinLit:phi0978.phi001:4.\"))\n",
    "\n",
    "Count_Annotations = 0 ## count the number of annotations detected\n",
    "\n",
    "for Paragraph in Book_4: ## for each paragraph in Book 4 \n",
    "\n",
    "    Reference = Paragraph.get(\"id\") ## get the ID of the paragraph (book, chapter, paragraph)\n",
    "    a_tags = Paragraph.find_all('a') ## get all a tags in the paragraph\n",
    "    \n",
    "    for a_tag in a_tags: ## for each a tag\n",
    "        \n",
    "        Tagged_Entity = a_tag.get_text() ## get the word content in the tag\n",
    "        Class = a_tag.get('class') ## get the class\n",
    "        Start_Position = Start_Positions_Annotations_Book4[Count_Annotations] ## get the start position in the list created above, the index is equal to the number of annotations already detected\n",
    "        End_Position = Start_Position+len(Tagged_Entity) ## the end position is equal to the sum of start pos and the lenght of the string\n",
    "        \n",
    "        ToposText_ID_about = a_tag.get('about') ## extract the content of \"about\"\n",
    "        ToposText_ID_href = a_tag.get('href') ## extract the content of \"href\"\n",
    "        \n",
    "        if ToposText_ID_href : ## if the tag contains \"href\"\n",
    "            ToposText_ID_href = \"https://topostext.org\"+ToposText_ID_href ## create the complete link of href\n",
    "        \n",
    "        f.writerow([Reference, Tagged_Entity, Class, Start_Position, End_Position, ToposText_ID_about, ToposText_ID_href])\n",
    "        Count_Annotations += 1\n",
    "        \n",
    "print(Reference, Tagged_Entity, Class, Start_Position, End_Position, ToposText_ID_about, ToposText_ID_href) ##print an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "194d011f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1888"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Count_Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ef87c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read the csv file\n",
    "ToposText_Book4 = pd.read_csv(\"/Users/u0154817/OneDrive - KU Leuven/Documents/KU Leuven/PhD project 'Greek Spaces in Roman Times'/Data_Extraction/Python Scripts/1.1.ToposText_Annotations_Book_4_TEMP.csv\", delimiter=\",\")\n",
    "len(ToposText_Book4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccde75b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## replace missing values in ToposText ID with values from Temporary_ToposTextID_href\n",
    "ToposText_Book4['ToposText ID'] = ToposText_Book4['ToposText ID'].fillna(ToposText_Book4['Temporary_ToposTextID_href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9f3a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ToposText_Book4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a12c554",
   "metadata": {},
   "outputs": [],
   "source": [
    "ToposText_Book4 = ToposText_Book4.drop(['Temporary_ToposTextID_href'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c16cea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ToposText_Book4.to_csv(\"1.1.ToposText_Annotations_Book_4.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
