{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce0b4e64",
   "metadata": {},
   "source": [
    "# Evaluation of the Enriched ToposText Annotation in Book 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3b5963",
   "metadata": {},
   "source": [
    "We performed an evaluation of the enriched ToposText annotation by calculating Precision, Recall, and F1 Score. By combining the results of the ToposText annotation with the output of the Flair ner-large system, the Recall of the ToposText annotation significantly improved from 0.671 to 0.968, accompanied by a substantial reduction in false negatives from 635 to 61. On the other hand, the Precision exhibited a slight decrease from 0.991 to 0.949, leading to an increase in false positives from 11 to 99.\n",
    "\n",
    "Overall, there is a notable enhancement in the annotation quality, as evidenced by the F1 Score which progressed from 0.800 to 0.958."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faa0152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "683b9f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "## open the Gold Standard of Book 4 (18,664 rows)\n",
    "GoldStandard_Book4 = pd.read_excel(\"/Users/u0154817/OneDrive - KU Leuven/Documents/KU Leuven/PhD project 'Greek Spaces in Roman Times'/Data_Extraction/Outputs/1.4.GoldStandard_Book4.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e955c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18664"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(GoldStandard_Book4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25b1bd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## open the file containing the enriched ToposText annotation (18,664 entries)\n",
    "Enriched_ToposText_Book4 = pd.read_csv(\"/Users/u0154817/OneDrive - KU Leuven/Documents/KU Leuven/PhD project 'Greek Spaces in Roman Times'/Data_Extraction/Outputs/3.2.Enriched_ToposText_Book4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b05ddebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18664"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Enriched_ToposText_Book4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bdce981",
   "metadata": {},
   "outputs": [],
   "source": [
    "## append the Gold Standard to the dataset of the enriched ToposText annotation\n",
    "Enriched_ToposText_Book4['Manual_Annotation'] = GoldStandard_Book4['Manual_Annotation']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c2235e",
   "metadata": {},
   "source": [
    "**Compute True Positive and False Negatives including partial matches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86210196",
   "metadata": {},
   "outputs": [],
   "source": [
    "True_Positives = [] ## create a list of true positives\n",
    "False_Negatives = [] ## create a list of false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6eac997",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, manual_annotation in enumerate(Enriched_ToposText_Book4['Manual_Annotation']): ## for each token\n",
    "        \n",
    "    if manual_annotation == 'B-LOC': ## for each B-LOC entity in the Gold Standard\n",
    "        \n",
    "        ## create a tuple containing the reference and start position\n",
    "        reference_startpos = (Enriched_ToposText_Book4['Reference'][index], Enriched_ToposText_Book4['Start_pos'][index])\n",
    "        \n",
    "        if len(Enriched_ToposText_Book4['ToposText_update'][index]) > 1: ## if the enriched ToposText contains an annotation\n",
    "            True_Positives.append(reference_startpos) ## it is a true positive\n",
    "            \n",
    "        else: ## if the the enriched ToposText does not contain an annotation\n",
    "            \n",
    "            if Enriched_ToposText_Book4['Manual_Annotation'][index+1] != 'I-LOC': ## if B-LOC is not followed by I-LOC\n",
    "                False_Negatives.append(reference_startpos) ## it is a false negative\n",
    "            \n",
    "            else: ## if B-LOC is followed by I-LOC\n",
    "                \n",
    "                flag = False\n",
    "                \n",
    "                for n in range(1,100):\n",
    "                    \n",
    "                    if Enriched_ToposText_Book4['Manual_Annotation'][index+n] == 'I-LOC': ## inside the multi-word LOC entity\n",
    "                        \n",
    "                        if len(Enriched_ToposText_Book4['ToposText_update'][index+n]) > 1: ## the enriched ToposText contains an annotation\n",
    "                            True_Positives.append((Enriched_ToposText_Book4['Reference'][index+n], Enriched_ToposText_Book4['Start_pos'][index+n])) ## it is a true positive\n",
    "                            flag = True\n",
    "                            break\n",
    "                            \n",
    "                    else: break\n",
    "                        \n",
    "                if flag == False: ## no entity was predicted in the span\n",
    "                    False_Negatives.append(reference_startpos) ## it is a false negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c62e3d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1870"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(True_Positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8afce7a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(False_Negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3cb78e",
   "metadata": {},
   "source": [
    "**Compute False Positives**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4c8830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "False_Positives = [] ## create a list of false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a80b805",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, ToposText_annotation in enumerate(Enriched_ToposText_Book4['ToposText_update']):\n",
    "        \n",
    "    if 'B-' in ToposText_annotation: ## for each B-place ToposText annotation\n",
    "        \n",
    "        ## create a tuple containing the reference and start position\n",
    "        reference_startpos = (Enriched_ToposText_Book4['Reference'][index], Enriched_ToposText_Book4['Start_pos'][index])\n",
    "        \n",
    "        if len(Enriched_ToposText_Book4['Manual_Annotation'][index]) == 1: ## if the Gold Standard does not contain an entity\n",
    "            \n",
    "            if 'I-' not in Enriched_ToposText_Book4['ToposText_update'][index+1]: ## if B-place is not followed by I-place\n",
    "                False_Positives.append(reference_startpos) ## it is a false positive\n",
    "        \n",
    "        else: ## if B-place is followed by I-place\n",
    "            \n",
    "            flag = False\n",
    "            \n",
    "            for n in range(1,100):\n",
    "                \n",
    "                if 'I-' in Enriched_ToposText_Book4['ToposText_update'][index+1]: ## inside the multi-word place annotation\n",
    "                    \n",
    "                    if len(Enriched_ToposText_Book4['Manual_Annotation'][index+n]) > 1: ## the Gold Standard contains an entity\n",
    "                        flag = True\n",
    "                        break\n",
    "                        \n",
    "                else: break\n",
    "                        \n",
    "                if flag == False:\n",
    "                    False_Positives.append(reference_startpos) ## it is a false positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64605fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(False_Positives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b08cef",
   "metadata": {},
   "source": [
    "The enriched ToposText annotation has a Precision of 0.949."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3b748f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9497206703910615"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## calculate precision\n",
    "\n",
    "Precision = len(True_Positives) / (len(True_Positives) + len(False_Positives))\n",
    "Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643179e9",
   "metadata": {},
   "source": [
    "The enriched ToposText annotation has a Recall of 0.968."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fa6c498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9684101501812532"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## calculate recall\n",
    "\n",
    "Recall = len(True_Positives) / (len(True_Positives) + len(False_Negatives))\n",
    "Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7c397b",
   "metadata": {},
   "source": [
    "The enriched ToposText annotation has a F1 Score of 0.958."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f95050a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9589743589743589"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## calculate F1 Score\n",
    "\n",
    "F1 = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "F1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
